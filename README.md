# DiffusionRenderer (Cosmos): Neural Inverse and Forward Rendering with Video Diffusion Models

![img](asset/teaser.gif)

**Overview.**
Cosmos Diffusion Renderer is a video diffusion framework for high-quality image and video de-lighting and re-lighting.
It extends our original [DiffusionRenderer](https://research.nvidia.com/labs/toronto-ai/DiffusionRenderer/) method by leveraging the powerful Cosmos video model and an improved data curation pipeline.
The resulting models enable accurate geometry and material estimation, generate higher-quality relighting results, and support longer video sequences, providing a general-purpose framework for video lighting control, randomization, and editing. 

**[Paper](https://arxiv.org/abs/2501.18590) | [Project Page](https://research.nvidia.com/labs/toronto-ai/DiffusionRenderer/)**


## News 
-  [June 11, 2025] Released our [video demo](https://www.youtube.com/watch?v=Q3xhYNbXM9c) and [blog](https://blogs.nvidia.com/blog/cvpr-2025-ai-research-diffusionrenderer/) on Cosmos Diffusion Renderer. 
-  [June 11, 2025] Released the code and model weights for the academic version of DiffusionRenderer. This version reproduces the results in our paper. Explore the [GitHub repo](https://github.com/nv-tlabs/diffusion-renderer) and [model weights](https://huggingface.co/collections/nexuslrf/diffusionrenderer-svd-68472d636e85c29b6c25422f)! 

## Installation
<p align="center">:construction: :pick: :hammer_and_wrench: :construction_worker:</p>
<p align="center">Under construction. Stay tuned!</p>




